{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **The Math Behind the Magic: Neural Networks, Theory and Practice**\n",
        "## **Encuentro Nacional de Ingeniería Matemática 2024**\n",
        "### ***Realizado por: Joaquín Fontbona, Javier Maass y Diego Olguín.***"
      ],
      "metadata": {
        "id": "c7bvnULhGUfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sesión 3: Todo es una red neuronal feedforward**"
      ],
      "metadata": {
        "id": "WgmW8ELQXPav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 1: PINNs para EDO**"
      ],
      "metadata": {
        "id": "3AqBY-XbXkVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero importamos las librerías y configuramos la semilla aleatoria."
      ],
      "metadata": {
        "id": "jd-etCrxXwS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yc8vJWKi3Hh3"
      },
      "outputs": [],
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Numpy\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "# Plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "\n",
        "# Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Para mostrar el progreso del entrenamiento\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Solo para dibujar el grafo de la red\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Solo para las animaciones\n",
        "from IPython.display import Image, HTML, display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Semilla aleatoria\n",
        "seed = 42\n",
        "\n",
        "# Fijamos la semilla para Pytorch y Numpy\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Si lo desean, pueden \"acelerar\" la velocidad de entrenamiento de sus redes neuronales\n",
        "# al utilizar la GPU de sus computadores (o cambiando el Runtime Type en Colab a uno con GPU)\n",
        "# Si esto les presenta errores extraños ligados a \"CUDA\", les recomiendo settear esta variable\n",
        "# como \"cpu\" (todo el notebook corre sin necesidad de usar GPU).\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "u1p4F54ziHcJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplificaremos el funcionamiento de una PINN con un sistema SIR simple\n",
        "\n",
        "\\begin{align*}\n",
        "\\frac{dS}{dt} &= -\\beta S I \\\\\n",
        "\\frac{dI}{dt} &= \\beta S I - \\gamma I \\\\\n",
        "\\frac{dS}{dt} &= \\gamma I\n",
        "\\end{align*}\n",
        "\n",
        "Para ello primero trabajaremos con datos sintéticos."
      ],
      "metadata": {
        "id": "M1DEaZvMHOrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase para poder crear datos sintéticos de un modelo SIR\n",
        "\n",
        "class SIR:\n",
        "    def __init__(self, beta, gamma):\n",
        "        # Guardamos los parámetros\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "\n",
        "    # Función de paso, pensando en integrar el sistema\n",
        "    def step(self, S, I, R):\n",
        "        dS = -self.beta * S * I\n",
        "        dI = self.beta * S * I - self.gamma * I\n",
        "        dR = self.gamma * I\n",
        "\n",
        "        return dS, dI, dR\n",
        "\n",
        "    # Simularemos con un método de Euler con paso constante igual a 1 día\n",
        "    def simulate(self, S0, I0, R0, T):\n",
        "        # Condición inicial\n",
        "        S = [S0]\n",
        "        I = [I0]\n",
        "        R = [R0]\n",
        "\n",
        "        # Evolución en cada día\n",
        "        for t in range(T-1):\n",
        "            dS, dI, dR = self.step(S[-1], I[-1], R[-1])\n",
        "            S.append(S[-1] + dS)\n",
        "            I.append(I[-1] + dI)\n",
        "            R.append(R[-1] + dR)\n",
        "\n",
        "        return np.array(S), np.array(I), np.array(R)\n",
        "\n",
        "    # Gráfico de la simulación\n",
        "    def plot_simulation(self, S, I, R, t):\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Scatter(x=t, y=S, name=\"Susceptibles\"))\n",
        "        fig.add_trace(go.Scatter(x=t, y=I, name=\"Infectados\"))\n",
        "        fig.add_trace(go.Scatter(x=t, y=R, name=\"Recuperados\"))\n",
        "        text_t = f\"Ajuste de parámetros: beta = {self.beta}, gamma = {self.gamma}\"\n",
        "        fig.update_layout(title=text_t, xaxis_title=\"Tiempo\", yaxis_title=\"Población normalizada\")\n",
        "        fig.show()\n",
        "        return fig,"
      ],
      "metadata": {
        "id": "yHSXXdMk4aUu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación modelo SIR\n",
        "\n",
        "# Parámetros\n",
        "true_beta = 1.1\n",
        "true_gamma = 0.5\n",
        "\n",
        "# Condiciones iniciales\n",
        "S0, I0, R0 = 0.95, 0.05, 0.0\n",
        "\n",
        "# Horizonte de tiempo\n",
        "T = 30\n",
        "\n",
        "# Instanciamos\n",
        "SIR_model = SIR(beta=true_beta, gamma=true_gamma)\n",
        "# Simulamos\n",
        "S, I, R = SIR_model.simulate(S0, I0, R0, T)\n",
        "# Graficamos\n",
        "fig, = SIR_model.plot_simulation(S, I, R, np.arange(T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "c5wTj63_pFeu",
        "outputId": "4c128adb-2258-4cf2-f362-d0a5bcb8ef03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4b27dc0d-36d4-4d87-8e1c-227a315cc4ca\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4b27dc0d-36d4-4d87-8e1c-227a315cc4ca\")) {                    Plotly.newPlot(                        \"4b27dc0d-36d4-4d87-8e1c-227a315cc4ca\",                        [{\"name\":\"Susceptibles\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0.95,0.8977499999999999,0.82146369375,0.7176286810556612,0.5903071924992876,0.4552664509354052,0.3355648056809444,0.24726592914828197,0.19071712332658372,0.15704566392471803,0.1373655609451348,0.12578490562261707,0.11888039491396125,0.11471474666477652,0.11217925867336019,0.1106266629683474,0.10967217498873569,0.10908389981495818,0.1087207514798617,0.10849635185020842,0.10835760242050683,0.10827177841369402,0.10821867884885653,0.1081858210859779,0.10816548697427578,0.1081529024353741,0.10814511373814999,0.10814029312948993,0.1081373095003632,0.10813546282117058],\"type\":\"scatter\"},{\"name\":\"Infectados\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0.05,0.07725,0.11491130625000001,0.1612906658193387,0.20796682146604298,0.239024152296904,0.2392137214029128,0.20790573723411881,0.16050167443875765,0.11392229662124453,0.07664125129020548,0.04990128096762046,0.031855151192466055,0.020093223845417767,0.012582099914125204,0.007843645662075387,0.0048763108106494035,0.0030264305791022073,0.0018763636246475859,0.001162581441977072,0.0007200401506901298,0.00044584408215787613,0.0002760216059164379,0.00017086856583683726,0.00010576839462054451,0.00006546873621195268,0.00004052306533008476,0.000025082141325096928,0.000015524699789280867,9.609029087255491e-6],\"type\":\"scatter\"},{\"name\":\"Recuperados\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0.0,0.025,0.063625,0.121080653125,0.20172598603466935,0.3057093967676908,0.4252214729161428,0.5448283336175992,0.6487812022346586,0.7290320394540375,0.7859931877646598,0.8243138134097625,0.8492644538935727,0.8651920294898058,0.8752386414125146,0.8815296913695773,0.885451514200615,0.8878896696059396,0.8894028848954907,0.8903410667078144,0.890922357428803,0.8912823775041481,0.8915052995452271,0.8916433103481852,0.8917287446311036,0.8917816288284139,0.89181436319652,0.891834624729185,0.8918471657998475,0.8918549281497421],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Ajuste de parámetros: beta = 1.1, gamma = 0.5\"},\"xaxis\":{\"title\":{\"text\":\"Tiempo\"}},\"yaxis\":{\"title\":{\"text\":\"Población normalizada\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4b27dc0d-36d4-4d87-8e1c-227a315cc4ca');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero veamos que pasa si no integramos la dinámica del problema y solo intentamos minimizar la pérdida asociada a los datos."
      ],
      "metadata": {
        "id": "mScBFEOlHR0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensiones de entrada y salida\n",
        "n_in, n_out = 1, 3"
      ],
      "metadata": {
        "id": "wxEGO2ALIOLw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una red neuronal que será la PINN. Notar que en realidad una PINN no es una arquitectura nueva, es solo otra forma de llamarle a una FFNN, la diferencia vendrá al momento de declarar la función de pérdida."
      ],
      "metadata": {
        "id": "6qQUIDe75jMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Una clase que creará una red neuronal del ancho y profundida que le demos\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, wide, deep):\n",
        "        super(PINN, self).__init__()\n",
        "        self.wide = wide # Ancho\n",
        "        self.deep = deep # Profundidad\n",
        "        # Capa de entrada\n",
        "        self.layers = nn.ModuleList([nn.Linear(n_in, self.wide)])\n",
        "        # Capas ocultas\n",
        "        self.layers.extend([nn.Linear(self.wide, self.wide) for _ in range(self.deep - 1)])\n",
        "        # Capa de salida\n",
        "        self.layers.append(nn.Linear(self.wide, n_out))\n",
        "        # Función de activación\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.activation(layer(x))\n",
        "        return self.layers[-1](x)"
      ],
      "metadata": {
        "id": "hlFb9cwXGwp8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenaremos con ciertos datos y luego veremos cómo la red generaliza a tiempos futuros."
      ],
      "metadata": {
        "id": "bVPZvSt76kBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos datos sintéticos\n",
        "T_data = 10\n",
        "t_obs = np.arange(T_data)\n",
        "S_obs, I_obs, R_obs = SIR_model.simulate(S0, I0, R0, T=T_data)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs, dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs, dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs, dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Definimos la función de pérdida, de una manera un poco diferente a cómo\n",
        "# lo hemos hecho antes, pero sigue siendo válida\n",
        "def loss_function(model, t_data, S_data, I_data, R_data):\n",
        "    t_data.requires_grad_(True)\n",
        "    SIR_pred_data = model(t_data)\n",
        "    S_pred_data, I_pred_data, R_pred_data = SIR_pred_data[:, 0:1], SIR_pred_data[:, 1:2], SIR_pred_data[:, 2:3]\n",
        "\n",
        "    # Pérdida de los datos observados\n",
        "    loss = torch.mean((S_pred_data - S_data)**2) + torch.mean((I_pred_data - I_data)**2) + torch.mean((R_pred_data - R_data)**2)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Instanciamos la clase\n",
        "wide, deep = 200, 1\n",
        "model = PINN(wide, deep)\n",
        "\n",
        "# Entrenamiento\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 3000\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_function(model, t_data_tensor, S_tensor, I_tensor, R_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHFzMGanI2G6",
        "outputId": "bdcb1fc7-4c8a-47b3-b57e-b3108bed5dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.553119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados junto con resultados de testeo\n",
        "T_test = 30\n",
        "\n",
        "t_test = torch.linspace(0, T_test-1, T_test).view(-1, 1)\n",
        "SIR_pred = model(t_test).detach().numpy()\n",
        "\n",
        "S, I, R = SIR_model.simulate(S0, I0, R0, T=T_test)\n",
        "\n",
        "# Gráfico con plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "\n",
        "# Observaciones\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=S_obs, mode='markers', name='S Observado', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=I_obs, mode='markers', name='I Observado', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=R_obs, mode='markers', name='R Observado', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Predicción\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 0], mode='lines', name='S Predicho', marker=dict(color='blue'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 1], mode='lines', name='I Predicho', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 2], mode='lines', name='R Predicho', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Real\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(T_test), y=S, mode='lines', name='S Real', marker=dict(color='blue'), line=dict(dash='dash'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(T_test), y=I, mode='lines', name='I Real', marker=dict(color='red'), line=dict(dash='dash'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(T_test), y=R, mode='lines', name='R Real', marker=dict(color='orange'), line=dict(dash='dash'))\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Resultado red sin información de la física del problema\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "iILUTsbmClTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora haremos exactamente lo mismo, pero ahora incluiremos en la pérdida un término que minimice el error de aproximar la ecuación diferencial."
      ],
      "metadata": {
        "id": "ADz5c6P6HsJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos datos sintéticos\n",
        "T_data, T_phys = 10, 30\n",
        "t_obs = np.arange(T_data)\n",
        "S_obs, I_obs, R_obs = SIR_model.simulate(S0, I0, R0, T=T_data)\n",
        "\n",
        "# Puntos de colocación\n",
        "t_phys = np.arange(0, T_phys, 2)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs, dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs, dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs, dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs, dtype=torch.float32).view(-1, 1)\n",
        "t_phys_tensor = torch.tensor(t_phys, dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs, dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs, dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Definimos la pérdida total, ahora incluyendo los términos de la dinámica\n",
        "def loss_function(model, t_phys, t_data, S_data, I_data, R_data):\n",
        "    t_data.requires_grad_(True)\n",
        "    t_phys.requires_grad_(True)\n",
        "    SIR_pred_data = model(t_data)\n",
        "    SIR_pred_phys = model(t_phys)\n",
        "    S_pred_data, I_pred_data, R_pred_data = SIR_pred_data[:, 0:1], SIR_pred_data[:, 1:2], SIR_pred_data[:, 2:3]\n",
        "    S_pred_phys, I_pred_phys, R_pred_phys = SIR_pred_phys[:, 0:1], SIR_pred_phys[:, 1:2], SIR_pred_phys[:, 2:3]\n",
        "\n",
        "    # Derivadas temporales\n",
        "    dS_dt = torch.autograd.grad(S_pred_phys, t_phys, grad_outputs=torch.ones_like(S_pred_phys), create_graph=True)[0]\n",
        "    dI_dt = torch.autograd.grad(I_pred_phys, t_phys, grad_outputs=torch.ones_like(I_pred_phys), create_graph=True)[0]\n",
        "    dR_dt = torch.autograd.grad(R_pred_phys, t_phys, grad_outputs=torch.ones_like(R_pred_phys), create_graph=True)[0]\n",
        "\n",
        "    # Ecuaciones diferenciales\n",
        "    beta = true_beta\n",
        "    gamma = true_gamma\n",
        "    eq1 = dS_dt + beta * S_pred_phys * I_pred_phys\n",
        "    eq2 = dI_dt - beta * S_pred_phys * I_pred_phys + gamma * I_pred_phys\n",
        "    eq3 = dR_dt - gamma * I_pred_phys\n",
        "\n",
        "    # Pérdida de las ecuaciones físicas\n",
        "    physics_loss = torch.mean(eq1**2) + torch.mean(eq2**2) + torch.mean(eq3**2)\n",
        "\n",
        "    # Pérdida de los datos observados\n",
        "    data_loss = torch.mean((S_pred_data - S_data)**2) + torch.mean((I_pred_data - I_data)**2) + torch.mean((R_pred_data - R_data)**2)\n",
        "\n",
        "    # Ponderadores de las pérdidas\n",
        "    w_phys = 0.5\n",
        "    w_data = 0.5\n",
        "\n",
        "    return w_phys*physics_loss + w_data*data_loss, physics_loss, data_loss\n",
        "\n",
        "# Instanciamos la clase\n",
        "wide, deep = 200, 1\n",
        "model = PINN(wide, deep)\n",
        "\n",
        "# Entrenamiento\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 5000\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss, phys_loss, data_loss = loss_function(model, t_phys_tensor, t_data_tensor, S_tensor, I_tensor, R_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "        print(f\"Loss Physics: {phys_loss.item():.6f}\")\n",
        "        print(f\"Loss Data: {data_loss.item():.6f}\")\n",
        "        print(\"\")"
      ],
      "metadata": {
        "id": "_TAYZYykGdd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados junto con resultados de testeo\n",
        "T_test = 30\n",
        "\n",
        "t_test = torch.linspace(0, T_test-1, T_test).view(-1, 1)\n",
        "SIR_pred = model(t_test).detach().numpy()\n",
        "\n",
        "S, I, R = SIR_model.simulate(S0, I0, R0, T=T_test)\n",
        "\n",
        "# Gráfico con plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Observaciones\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=S_obs, mode='markers', name='S Observado', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=I_obs, mode='markers', name='I Observado', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=R_obs, mode='markers', name='R Observado', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Predicción\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 0], mode='lines', name='S Predicho', marker=dict(color='blue'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 1], mode='lines', name='I Predicho', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 2], mode='lines', name='R Predicho', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Real\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(T_test), y=S, mode='lines', name='S Real', marker=dict(color='blue'), line=dict(dash='dash'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(T_test), y=I, mode='lines', name='I Real', marker=dict(color='red'), line=dict(dash='dash'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(T_test), y=R, mode='lines', name='R Real', marker=dict(color='orange'), line=dict(dash='dash'))\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Resultado red con información de la física del problema\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "MI1niXclHfnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Vemos que el resultado de generalizar es mucho mejor que solo con los datos!"
      ],
      "metadata": {
        "id": "cx1E0-7zJ-t4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pero podemos aprovecharnos de que tenemos física incluida en la función de pérdida, ya que ahora podemos estimar los parámetros $\\beta$ y $\\gamma$ del modelo SIR en base a datos. Esto dará paso a en realidad un modelo que ahora podemos simular con un solver de EDO, por ejemplo, también pueden ser parámetros que tienen un valor tangible, como el número básico reproductivo en epidemiología.\n",
        "\n",
        "Esto se puede hacer en PyTorch de manera muy sencilla, agregándolos como parámetros sujetos a aprendizaje."
      ],
      "metadata": {
        "id": "FWsvDGJBKgZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Una clase que creará una red neuronal del ancho y profundida que le demos\n",
        "class PINN_params(nn.Module):\n",
        "    def __init__(self, wide, deep):\n",
        "        super(PINN_params, self).__init__()\n",
        "        self.wide = wide # Ancho\n",
        "        self.deep = deep # Profundidad\n",
        "        # Capa de entrada\n",
        "        self.layers = nn.ModuleList([nn.Linear(n_in, self.wide)])\n",
        "        # Capas ocultas\n",
        "        self.layers.extend([nn.Linear(self.wide, self.wide) for _ in range(self.deep - 1)])\n",
        "        # Capa de salida\n",
        "        self.layers.append(nn.Linear(self.wide, n_out))\n",
        "        # Función de activación\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "        # Parámetros a aprender\n",
        "        self.beta = nn.Parameter(torch.tensor(0.1, dtype=torch.float32))  # Valor inicial para beta\n",
        "        self.gamma = nn.Parameter(torch.tensor(0.1, dtype=torch.float32))  # Valor inicial para gamma\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.activation(layer(x))\n",
        "        return self.layers[-1](x)"
      ],
      "metadata": {
        "id": "uN35Lt2ELOgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notar que hay que colocar una restricción a los parámetros en este modelo, y es que $\\beta$ y $\\gamma$ deben ser positivos para que todo tenga sentido. Eso se logra creando un Clipper para aplicarlo a la red."
      ],
      "metadata": {
        "id": "bIyZxxlIO9PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightClipper(object):\n",
        "\n",
        "    def __init__(self, frequency=5):\n",
        "        self.frequency = frequency\n",
        "\n",
        "    def __call__(self, module):\n",
        "        # filter the variables to get the ones you want\n",
        "        if hasattr(module, 'weight'):\n",
        "            w = module.weight.data\n",
        "            w = w.clamp(0,10)"
      ],
      "metadata": {
        "id": "bgLMekqu7lTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtendremos los datos desde un archivo de datos en el GitHub del curso."
      ],
      "metadata": {
        "id": "mXbLoUSenKOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonamos el GitHub del curso\n",
        "!git clone https://github.com/diegoolguinw/Math_Behind_Magic.git"
      ],
      "metadata": {
        "id": "wh3xiuYUnXHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrimos el archivo de datos\n",
        "data = pd.read_csv('Math_Behind_Magic/Data/epi_data.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "EHxntGplnwPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraemos los arreglos\n",
        "S_obs = data['Susceptibles'].values\n",
        "I_obs = data['Infectados'].values\n",
        "R_obs = data['Recuperados'].values"
      ],
      "metadata": {
        "id": "osj__KFjn0Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supondremos que no nos llegan todos los datos a la vez, si no que nos van llegando por día, entonces tenemos que entrenar el model con una cierta cantidad de datos cada día. Haremos el setting inicial y luego vamos aplicando el entrenamiento día a día."
      ],
      "metadata": {
        "id": "7WJx2aDa3QmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Puntos de colocación\n",
        "T_phys = 20\n",
        "t_phys = np.arange(0, T_phys, 2)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs, dtype=torch.float32).view(-1, 1)\n",
        "t_phys_tensor = torch.tensor(t_phys, dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs, dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs, dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Definimos la pérdida total, ahora incluyendo los términos de la dinámica\n",
        "def loss_function(model, t_phys, t_data, S_data, I_data, R_data):\n",
        "    t_data.requires_grad_(True)\n",
        "    t_phys.requires_grad_(True)\n",
        "    SIR_pred_data = model(t_data)\n",
        "    SIR_pred_phys = model(t_phys)\n",
        "    S_pred_data, I_pred_data, R_pred_data = SIR_pred_data[:, 0:1], SIR_pred_data[:, 1:2], SIR_pred_data[:, 2:3]\n",
        "    S_pred_phys, I_pred_phys, R_pred_phys = SIR_pred_phys[:, 0:1], SIR_pred_phys[:, 1:2], SIR_pred_phys[:, 2:3]\n",
        "\n",
        "    # Derivadas temporales\n",
        "    dS_dt = torch.autograd.grad(S_pred_phys, t_phys, grad_outputs=torch.ones_like(S_pred_phys), create_graph=True)[0]\n",
        "    dI_dt = torch.autograd.grad(I_pred_phys, t_phys, grad_outputs=torch.ones_like(I_pred_phys), create_graph=True)[0]\n",
        "    dR_dt = torch.autograd.grad(R_pred_phys, t_phys, grad_outputs=torch.ones_like(R_pred_phys), create_graph=True)[0]\n",
        "\n",
        "    # Solo cambian estas lineas al estimar parámetros!\n",
        "    beta = model.beta\n",
        "    gamma = model.gamma\n",
        "\n",
        "    # Ecuaciones diferenciales\n",
        "    eq1 = dS_dt + beta * S_pred_phys * I_pred_phys\n",
        "    eq2 = dI_dt - beta * S_pred_phys * I_pred_phys + gamma * I_pred_phys\n",
        "    eq3 = dR_dt - gamma * I_pred_phys\n",
        "\n",
        "    # Pérdida de las ecuaciones físicas\n",
        "    physics_loss = torch.mean(eq1**2) + torch.mean(eq2**2) + torch.mean(eq3**2)\n",
        "\n",
        "    # Pérdida de los datos observados\n",
        "    data_loss = torch.mean((S_pred_data - S_data)**2) + torch.mean((I_pred_data - I_data)**2) + torch.mean((R_pred_data - R_data)**2)\n",
        "\n",
        "    # Ponderadores de las pérdidas\n",
        "    w_phys = 0.5\n",
        "    w_data = 0.5\n",
        "\n",
        "    return w_phys*physics_loss + w_data*data_loss, physics_loss, data_loss\n",
        "\n",
        "# Instanciamos la clase\n",
        "wide, deep = 250, 1\n",
        "model = PINN_params(wide, deep)\n",
        "\n",
        "clipper = WeightClipper()\n",
        "model.beta.register_hook(clipper)\n",
        "model.gamma.register_hook(clipper)\n",
        "\n",
        "# Entrenamiento\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Guardaremos los resultados por día\n",
        "results_days = {}"
      ],
      "metadata": {
        "id": "GEBUa8yk5iQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento con hasta el día 1\n",
        "day = 1\n",
        "\n",
        "# Tiempo en los datos\n",
        "T_data = len(S_obs[:day])\n",
        "t_obs = np.arange(T_data)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Épocas de entrenamiento\n",
        "epochs = 10000\n",
        "\n",
        "print(f\"Entrenando en el día {day} con {epochs} épocas\")\n",
        "print(\"\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss, phys_loss, data_loss = loss_function(model, t_phys_tensor, t_data_tensor, S_tensor, I_tensor, R_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "        print(f\"Loss Physics: {phys_loss.item():.6f}\")\n",
        "        print(f\"Loss Data: {data_loss.item():.6f}\")\n",
        "        print(\"\")"
      ],
      "metadata": {
        "id": "5aeI3TPx2YZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados junto con resultados de testeo\n",
        "T_test = 20\n",
        "\n",
        "# Tiempo de testeo\n",
        "t_test = torch.linspace(0, T_test-1, T_test).view(-1, 1)\n",
        "\n",
        "# Colocamos el modelo en evaluación\n",
        "model.eval()\n",
        "SIR_pred = model(t_test).detach().numpy()\n",
        "results_days[day] = SIR_pred\n",
        "\n",
        "# Gráfico con plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Observaciones\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=S_obs, mode='markers', name='S Observado', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=I_obs, mode='markers', name='I Observado', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=R_obs, mode='markers', name='R Observado', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Predicción\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 0], mode='lines', name='S Predicho', marker=dict(color='blue'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 1], mode='lines', name='I Predicho', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 2], mode='lines', name='R Predicho', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Entrenamiento con datos hasta el día {day}\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\",\n",
        "    )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "MNIJzci83L0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento con hasta el día 2\n",
        "day = 2\n",
        "\n",
        "# Tiempo en los datos\n",
        "T_data = len(S_obs[:day])\n",
        "t_obs = np.arange(T_data)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Épocas de entrenamiento\n",
        "epochs = 2000\n",
        "\n",
        "print(f\"Entrenando en el día {day} con {epochs} épocas\")\n",
        "print(\"\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss, phys_loss, data_loss = loss_function(model, t_phys_tensor, t_data_tensor, S_tensor, I_tensor, R_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "        print(f\"Loss Physics: {phys_loss.item():.6f}\")\n",
        "        print(f\"Loss Data: {data_loss.item():.6f}\")\n",
        "        print(\"\")"
      ],
      "metadata": {
        "id": "1lRSpOP44vTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados junto con resultados de testeo\n",
        "T_test = 20\n",
        "\n",
        "# Tiempo de testeo\n",
        "t_test = torch.linspace(0, T_test-1, T_test).view(-1, 1)\n",
        "\n",
        "# Colocamos el modelo en evaluación\n",
        "model.eval()\n",
        "SIR_pred = model(t_test).detach().numpy()\n",
        "results_days[day] = SIR_pred\n",
        "\n",
        "# Gráfico con plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Observaciones\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=S_obs, mode='markers', name='S Observado', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=I_obs, mode='markers', name='I Observado', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=R_obs, mode='markers', name='R Observado', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Predicción\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 0], mode='lines', name='S Predicho', marker=dict(color='blue'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 1], mode='lines', name='I Predicho', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 2], mode='lines', name='R Predicho', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Entrenamiento con datos hasta el día {day}\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\",\n",
        "    )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "SMNum3Tk4zRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento con hasta el día 3\n",
        "day = 3\n",
        "\n",
        "# Tiempo en los datos\n",
        "T_data = len(S_obs[:day])\n",
        "t_obs = np.arange(T_data)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Épocas de entrenamiento\n",
        "epochs = 2000\n",
        "\n",
        "print(f\"Entrenando en el día {day} con {epochs} épocas\")\n",
        "print(\"\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss, phys_loss, data_loss = loss_function(model, t_phys_tensor, t_data_tensor, S_tensor, I_tensor, R_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "        print(f\"Loss Physics: {phys_loss.item():.6f}\")\n",
        "        print(f\"Loss Data: {data_loss.item():.6f}\")\n",
        "        print(\"\")"
      ],
      "metadata": {
        "id": "CezDF4TD40yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados junto con resultados de testeo\n",
        "T_test = 20\n",
        "\n",
        "# Tiempo de testeo\n",
        "t_test = torch.linspace(0, T_test-1, T_test).view(-1, 1)\n",
        "\n",
        "# Colocamos el modelo en evaluación\n",
        "model.eval()\n",
        "SIR_pred = model(t_test).detach().numpy()\n",
        "results_days[day] = SIR_pred\n",
        "\n",
        "# Gráfico con plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Observaciones\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=S_obs, mode='markers', name='S Observado', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=I_obs, mode='markers', name='I Observado', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=R_obs, mode='markers', name='R Observado', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Predicción\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 0], mode='lines', name='S Predicho', marker=dict(color='blue'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 1], mode='lines', name='I Predicho', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 2], mode='lines', name='R Predicho', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Entrenamiento con datos hasta el día {day}\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\",\n",
        "    )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "WUZ4_oEh411v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento con hasta el día 4\n",
        "day = 4\n",
        "\n",
        "# Tiempo en los datos\n",
        "T_data = len(S_obs[:day])\n",
        "t_obs = np.arange(T_data)\n",
        "\n",
        "# Convertimos a tensores\n",
        "t_data_tensor = torch.tensor(t_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "S_tensor = torch.tensor(S_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "I_tensor = torch.tensor(I_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "R_tensor = torch.tensor(R_obs[:day], dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Épocas de entrenamiento\n",
        "epochs = 5000\n",
        "\n",
        "print(f\"Entrenando en el día {day} con {epochs} épocas\")\n",
        "print(\"\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    loss, phys_loss, data_loss = loss_function(model, t_phys_tensor, t_data_tensor, S_tensor, I_tensor, R_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "        print(f\"Loss Physics: {phys_loss.item():.6f}\")\n",
        "        print(f\"Loss Data: {data_loss.item():.6f}\")\n",
        "        print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufazwo4t44eA",
        "outputId": "e9d04f62-7764-4cb2-9f7b-69c6c84f40aa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrenando en el día 4 con 5000 épocas\n",
            "\n",
            "Epoch 0, Loss: 0.000975\n",
            "Loss Physics: 0.000015\n",
            "Loss Data: 0.001935\n",
            "\n",
            "Epoch 500, Loss: 0.000114\n",
            "Loss Physics: 0.000031\n",
            "Loss Data: 0.000198\n",
            "\n",
            "Epoch 1000, Loss: 0.000073\n",
            "Loss Physics: 0.000024\n",
            "Loss Data: 0.000121\n",
            "\n",
            "Epoch 1500, Loss: 0.000061\n",
            "Loss Physics: 0.000031\n",
            "Loss Data: 0.000091\n",
            "\n",
            "Epoch 2000, Loss: 0.000051\n",
            "Loss Physics: 0.000018\n",
            "Loss Data: 0.000084\n",
            "\n",
            "Epoch 2500, Loss: 0.000018\n",
            "Loss Physics: 0.000011\n",
            "Loss Data: 0.000026\n",
            "\n",
            "Epoch 3000, Loss: 0.000450\n",
            "Loss Physics: 0.000252\n",
            "Loss Data: 0.000648\n",
            "\n",
            "Epoch 3500, Loss: 0.000024\n",
            "Loss Physics: 0.000010\n",
            "Loss Data: 0.000038\n",
            "\n",
            "Epoch 4000, Loss: 0.000005\n",
            "Loss Physics: 0.000003\n",
            "Loss Data: 0.000006\n",
            "\n",
            "Epoch 4500, Loss: 0.000030\n",
            "Loss Physics: 0.000016\n",
            "Loss Data: 0.000045\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados junto con resultados de testeo\n",
        "T_test = 20\n",
        "\n",
        "# Tiempo de testeo\n",
        "t_test = torch.linspace(0, T_test-1, T_test).view(-1, 1)\n",
        "\n",
        "# Colocamos el modelo en evaluación\n",
        "model.eval()\n",
        "SIR_pred = model(t_test).detach().numpy()\n",
        "results_days[day] = SIR_pred\n",
        "\n",
        "# Gráfico con plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Observaciones\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=S_obs, mode='markers', name='S Observado', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=I_obs, mode='markers', name='I Observado', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=R_obs, mode='markers', name='R Observado', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Predicción\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 0], mode='lines', name='S Predicho', marker=dict(color='blue'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 1], mode='lines', name='I Predicho', marker=dict(color='red'))\n",
        "    )\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test.numpy().squeeze(), y=SIR_pred[:, 2], mode='lines', name='R Predicho', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Entrenamiento con datos hasta el día {day}\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\",\n",
        "    )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0fAxlx4G4632",
        "outputId": "3cf7d840-e11b-4f8b-af7d-6aea4a2400b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"348d7b82-ea5a-48ad-80e5-472ab180abcd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"348d7b82-ea5a-48ad-80e5-472ab180abcd\")) {                    Plotly.newPlot(                        \"348d7b82-ea5a-48ad-80e5-472ab180abcd\",                        [{\"marker\":{\"color\":\"blue\",\"opacity\":0.9},\"mode\":\"markers\",\"name\":\"S Observado\",\"x\":[0,1,2,3],\"y\":[1.0,0.783,0.6028317,0.3784102441503569,0.1834853881899827],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers\",\"name\":\"I Observado\",\"x\":[0,1,2,3],\"y\":[0.1,0.177,0.2863683,0.396242435849643,0.43267031747016],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"markers\",\"name\":\"R Observado\",\"x\":[0,1,2,3],\"y\":[0.0,0.04,0.1108,0.22534732,0.3838442943398572],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\"},\"mode\":\"lines\",\"name\":\"S Predicho\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[1.0008868,0.78410625,0.602917,0.38029382,0.22104585,0.1304084,0.08260751,0.057279523,0.043100048,0.034502868,0.02887537,0.024993565,0.022260595,0.020357657,0.019092437,0.018332135,0.01797596,0.017942872,0.01816592,0.018589389],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"lines\",\"name\":\"I Predicho\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.101356976,0.1767616,0.28913686,0.39640364,0.42218044,0.38556388,0.32260936,0.25658545,0.19807637,0.15026876,0.112898596,0.084421046,0.06303655,0.047107257,0.03528603,0.02651947,0.020007528,0.015152805,0.011513822,0.008766256],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"R Predicho\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.0002722554,0.040856283,0.1111974,0.2251309,0.35861328,0.4882988,0.6014667,0.6940797,0.766895,0.8226929,0.8647435,0.8960932,0.9193047,0.9364158,0.94899595,0.9582286,0.96499664,0.9699536,0.97358054,0.9762313],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Entrenamiento con datos hasta el día 4\"},\"xaxis\":{\"title\":{\"text\":\"Tiempo\"}},\"yaxis\":{\"title\":{\"text\":\"Población normalizada\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('348d7b82-ea5a-48ad-80e5-472ab180abcd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparamos los resultados por día\n",
        "\n",
        "fig = go.Figure()\n",
        "for day in results_days.keys():\n",
        "\n",
        "    SIR_pred = results_days[day]\n",
        "\n",
        "    # Predicción\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=t_test.squeeze(), y=SIR_pred[:,0], mode='lines', name=f'S Datos al día {day}', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=t_test.squeeze(), y=SIR_pred[:,1], mode='lines', name=f'I Datos al día {day}', marker=dict(color='red'))\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=t_test.squeeze(), y=SIR_pred[:,2], mode='lines', name=f'R Datos al día {day}', marker=dict(color='orange'))\n",
        "    )\n",
        "\n",
        "# Observaciones\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=S_obs, mode='markers', name='S Observado', marker=dict(color='blue', opacity=0.9))\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=I_obs, mode='markers', name='I Observado', marker=dict(color='red'))\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_obs, y=R_obs, mode='markers', name='R Observado', marker=dict(color='orange'))\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Comparación de resultados por día\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "dKG7bU2c5o-X",
        "outputId": "d52b43f9-0c65-4192-9332-4ad934a27efb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7c710778-d725-4ec5-9058-8ff70b437775\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7c710778-d725-4ec5-9058-8ff70b437775\")) {                    Plotly.newPlot(                        \"7c710778-d725-4ec5-9058-8ff70b437775\",                        [{\"marker\":{\"color\":\"blue\",\"opacity\":0.9},\"mode\":\"lines\",\"name\":\"S Datos al día 1\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[1.0009704,1.0011619,1.0010179,1.0000561,0.99918675,0.9984809,0.997765,0.99699914,0.9962155,0.995441,0.9946798,0.9939256,0.99317056,0.9924091,0.99164003,0.99086446,0.990085,0.9893051,0.9885283,0.9877582],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"lines\",\"name\":\"I Datos al día 1\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.09975292,0.099828154,0.09994498,0.100259766,0.10054998,0.10077824,0.10101029,0.101263255,0.10152139,0.10177283,0.10201709,0.10225931,0.102504075,0.102753654,0.10300754,0.10326378,0.103519395,0.10377143,0.10401723,0.104254454],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"R Datos al día 1\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.0040822495,0.0049421955,0.005655946,0.006168904,0.0066961963,0.00723991,0.0077700038,0.008287581,0.008804562,0.009328039,0.009856405,0.010385187,0.010909351,0.011426004,0.011935564,0.01244125,0.012948783,0.013464989,0.013996484,0.0145503],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"opacity\":0.9},\"mode\":\"lines\",\"name\":\"S Datos al día 2\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.999886,0.78310275,0.5773185,0.44029155,0.3405583,0.26840085,0.21862496,0.18592717,0.1653745,0.15298954,0.1458538,0.14195095,0.13994484,0.13897868,0.13851953,0.13824709,0.13797736,0.13761245,0.13710703,0.13644771],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"lines\",\"name\":\"I Datos al día 2\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.100084856,0.17704934,0.23345254,0.24291952,0.21921445,0.18119492,0.14134938,0.1057753,0.076569214,0.053794652,0.036665484,0.024157152,0.015283279,0.009197623,0.005215429,0.0028002784,0.0015398636,0.0011212379,0.0013086274,0.0019251704],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"R Datos al día 2\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[-0.0005123522,0.039690636,0.13795659,0.27453044,0.4052516,0.5158084,0.603608,0.67051977,0.719994,0.7556981,0.78091043,0.7983214,0.8100299,0.8176262,0.8222897,0.82488304,0.82603127,0.82618415,0.8256637,0.8246974],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"opacity\":0.9},\"mode\":\"lines\",\"name\":\"S Datos al día 3\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.9983287,0.7830733,0.60024977,0.44099644,0.3108136,0.21730107,0.155483,0.11648587,0.092456155,0.07773057,0.06857326,0.06263297,0.058475085,0.05524876,0.052464806,0.04985472,0.047281615,0.044685297,0.042048253,0.03937555],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"lines\",\"name\":\"I Datos al día 3\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.09845634,0.17816867,0.28384373,0.3460165,0.35849467,0.33708817,0.29803148,0.25284305,0.20836401,0.16807699,0.13337772,0.104481444,0.08099972,0.06228144,0.047603708,0.03627074,0.027659204,0.021234106,0.01654796,0.013233926],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"R Datos al día 3\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.020019097,0.06050414,0.13118066,0.23185292,0.34370527,0.45289114,0.5515397,0.636413,0.7071235,0.76475966,0.8110283,0.8477739,0.8767358,0.89944124,0.9171767,0.9309955,0.9417424,0.9500884,0.95656,0.96156836],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"opacity\":0.9},\"mode\":\"lines\",\"name\":\"S Datos al día 4\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[1.0008868,0.78410625,0.602917,0.38029382,0.22104585,0.1304084,0.08260751,0.057279523,0.043100048,0.034502868,0.02887537,0.024993565,0.022260595,0.020357657,0.019092437,0.018332135,0.01797596,0.017942872,0.01816592,0.018589389],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"lines\",\"name\":\"I Datos al día 4\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.101356976,0.1767616,0.28913686,0.39640364,0.42218044,0.38556388,0.32260936,0.25658545,0.19807637,0.15026876,0.112898596,0.084421046,0.06303655,0.047107257,0.03528603,0.02651947,0.020007528,0.015152805,0.011513822,0.008766256],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"R Datos al día 4\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.0002722554,0.040856283,0.1111974,0.2251309,0.35861328,0.4882988,0.6014667,0.6940797,0.766895,0.8226929,0.8647435,0.8960932,0.9193047,0.9364158,0.94899595,0.9582286,0.96499664,0.9699536,0.97358054,0.9762313],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\",\"opacity\":0.9},\"mode\":\"markers\",\"name\":\"S Observado\",\"x\":[0,1,2,3],\"y\":[1.0,0.783,0.6028317,0.3784102441503569,0.1834853881899827],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers\",\"name\":\"I Observado\",\"x\":[0,1,2,3],\"y\":[0.1,0.177,0.2863683,0.396242435849643,0.43267031747016],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"markers\",\"name\":\"R Observado\",\"x\":[0,1,2,3],\"y\":[0.0,0.04,0.1108,0.22534732,0.3838442943398572],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Comparación de resultados por día\"},\"xaxis\":{\"title\":{\"text\":\"Tiempo\"}},\"yaxis\":{\"title\":{\"text\":\"Población normalizada\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7c710778-d725-4ec5-9058-8ff70b437775');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver el resultado de estimación de parámetros."
      ],
      "metadata": {
        "id": "K8O0cwWDIPYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraemos los valores de beta y gamma\n",
        "beta_pred = model.beta.item()\n",
        "gamma_pred = model.gamma.item()\n",
        "\n",
        "# Valores verdaderos de beta y gamma utilizados\n",
        "beta_true = 1.3\n",
        "gamma_true = 0.4\n",
        "\n",
        "# Printeamos\n",
        "print(f\"Beta Predicho: {beta_pred}\")\n",
        "print(f\"Gamma Predicho: {gamma_pred}\")\n",
        "print(\"\")\n",
        "print(f\"Beta Real: {beta_true}\")\n",
        "print(f\"Gamma Real: {gamma_true}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDDk7C0rEury",
        "outputId": "42d5fa69-b51f-436c-c6cd-3a0e3b4c9a3d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beta Predicho: 1.3088319301605225\n",
            "Gamma Predicho: 0.3205893635749817\n",
            "\n",
            "Beta Real: 1.3\n",
            "Gamma Real: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resolvemos con solve_ivp de Scipy\n",
        "from scipy.integrate import solve_ivp\n",
        "\n",
        "# Condición inicial\n",
        "S0, I0, R0 = S_obs[0], I_obs[0], R_obs[0]\n",
        "\n",
        "# Tiempo a evaluar\n",
        "t_test = np.linspace(0, T_test-1, T_test)\n",
        "\n",
        "def step_pred(t, y):\n",
        "    return np.array([\n",
        "        -beta_pred * y[0] * y[1],\n",
        "        beta_pred * y[0] * y[1] - gamma_pred * y[1],\n",
        "        gamma_pred * y[1]])\n",
        "\n",
        "def step_true(t, y):\n",
        "    return np.array([\n",
        "        -beta_true * y[0] * y[1],\n",
        "        beta_true * y[0] * y[1] - gamma_true * y[1],\n",
        "        gamma_true * y[1]])\n",
        "\n",
        "\n",
        "sol_pred = solve_ivp(step_pred, [0, T_test], [S0, I0, R0], t_eval=t_test)\n",
        "sol_true = solve_ivp(step_true, [0, T_test], [S0, I0, R0], t_eval=t_test)\n",
        "\n",
        "# Gráfico con Plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test, y=sol_pred.y[0], mode='lines', name='S Predicho', marker=dict(color='blue'))\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test, y=sol_pred.y[1], mode='lines', name='I Predicho', marker=dict(color='red'))\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test, y=sol_pred.y[2], mode='lines', name='R Predicho', marker=dict(color='orange'))\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test, y=sol_true.y[0], mode='lines', name='S Real', marker=dict(color='blue'), line=dict(dash='dash'))\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test, y=sol_true.y[1], mode='lines', name='I Real', marker=dict(color='red'), line=dict(dash='dash'))\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=t_test, y=sol_true.y[2], mode='lines', name='R Real', marker=dict(color='orange'), line=dict(dash='dash'))\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Comparación de resultados\",\n",
        "    xaxis_title=\"Tiempo\",\n",
        "    yaxis_title=\"Población normalizada\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0aPH0tKClGUz",
        "outputId": "051efb38-119c-4b53-bf2c-515364104cf5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9fb7c0f6-4ae6-4fd8-990c-b72f78051cdb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9fb7c0f6-4ae6-4fd8-990c-b72f78051cdb\")) {                    Plotly.newPlot(                        \"9fb7c0f6-4ae6-4fd8-990c-b72f78051cdb\",                        [{\"marker\":{\"color\":\"blue\"},\"mode\":\"lines\",\"name\":\"S Predicho\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[1.0,0.807524637853038,0.5233533558623207,0.28080515434179426,0.1453949094993476,0.07981275907076868,0.04968920904650255,0.034253480832764395,0.025895760601308153,0.021032795347389055,0.017966874399219214,0.016003066621457604,0.01474572166482813,0.013848436955309542,0.013209387917725478,0.012764318320111866,0.012443797361870252,0.01220931092938058,0.012040735754523416,0.011918265573046793],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"lines\",\"name\":\"I Predicho\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.1,0.24012896478602444,0.41806346629896823,0.5086649507772956,0.48294060434638925,0.4053542457035613,0.3194892760850564,0.24480903364893264,0.18470551552865394,0.1381486933432663,0.10280816062673907,0.07624091652781964,0.05645973551643532,0.041742328463675996,0.0308118937327186,0.022762815224722486,0.016806063046028993,0.012383679722059181,0.009136101105997486,0.0067446849427886995],\"type\":\"scatter\"},{\"marker\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"R Predicho\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.0,0.052346397360937616,0.15858317783871104,0.31052989488091,0.471664486154263,0.6148329952256699,0.7308215148684408,0.8209374855183027,0.8893987238700377,0.9408185113093445,0.9792249649740414,1.0077560168507225,1.0287945428187362,1.0444092345810143,1.0559787183495557,1.0644728664551655,1.0707501395921006,1.07540700934856,1.078823163139479,1.0813370494841643],\"type\":\"scatter\"},{\"line\":{\"dash\":\"dash\"},\"marker\":{\"color\":\"blue\"},\"mode\":\"lines\",\"name\":\"S Real\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[1.0,0.8168822277306023,0.5569826044287903,0.32836909397151853,0.18982527791660303,0.1173916872803438,0.08071907258425925,0.06095418634585104,0.049722106849401274,0.0430662248994036,0.03890924613047589,0.036182174247028104,0.03441634684144214,0.03322003931588113,0.03239982812431972,0.03184500359890411,0.031458738048684994,0.03119182779479862,0.031008093188939604,0.03087939096363832],\"type\":\"scatter\"},{\"line\":{\"dash\":\"dash\"},\"marker\":{\"color\":\"red\"},\"mode\":\"lines\",\"name\":\"I Real\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.1,0.22090012965487937,0.36298030018381977,0.4295836135193176,0.3998898636246366,0.32639376516257657,0.24837614520213852,0.18242953171408882,0.13135150577638532,0.09344457813921343,0.06603385296665121,0.046437155705009996,0.03260079370962517,0.02283832918857029,0.015963656453675847,0.011173931145230898,0.0078023912871627125,0.005446014060956147,0.0038083690162685722,0.0026572918564439687],\"type\":\"scatter\"},{\"line\":{\"dash\":\"dash\"},\"marker\":{\"color\":\"orange\"},\"mode\":\"lines\",\"name\":\"R Real\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0],\"y\":[0.0,0.06221764261451846,0.18003709538739002,0.342047292509164,0.5102848584587605,0.6562145475570799,0.7709047822136024,0.8566162819400602,0.9189263873742136,0.9634891969613832,0.9950569009028731,1.0173806700479622,1.032982859448933,1.0439416314955487,1.0516365154220046,1.056981065255865,1.0607388706641525,1.0633621581442454,1.065183537794792,1.066463317179918],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Comparación de resultados\"},\"xaxis\":{\"title\":{\"text\":\"Tiempo\"}},\"yaxis\":{\"title\":{\"text\":\"Población normalizada\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9fb7c0f6-4ae6-4fd8-990c-b72f78051cdb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incluso, podemos guardar el modelo para exportarlo y después guardarlo, por si viene otra pandemia en el futuro, para tener un red pre-entrenada!"
      ],
      "metadata": {
        "id": "Ye-o3TUPndl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos el modelo\n",
        "torch.save(model.state_dict(), \"SIR_Net.pt\")"
      ],
      "metadata": {
        "id": "mDlHxfWPnno4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y podemos cargarlo desde un GitHub\n",
        "model_PATH = 'Math_Behind_Magic/Data/SIR_Net.pt'\n",
        "model = PINN_params(wide, deep)\n",
        "model.load_state_dict(torch.load(model_PATH, weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4KM8-19oD5b",
        "outputId": "715cd567-1031-45d5-dac9-8e4bf0e7d9e7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 2: Principio de Continuación Única con PINNs**"
      ],
      "metadata": {
        "id": "rERwTBwJ-vIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este ejemplo utilizaremos la librería [DeepXDE](https://deepxde.readthedocs.io/en/latest/), que facilitará la implementación de este problema al tener que involucrarnos con geometrías y EDP. Ocuparemos como dominio un cuadrado perforado y trataremos de aproximar la solución de una ecuación de Laplace."
      ],
      "metadata": {
        "id": "yZjnAh2R-z88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar DeepXDE\n",
        "try:\n",
        "    import deepxde as dde\n",
        "except:\n",
        "    !pip install deepxde\n",
        "    import deepxde as dde"
      ],
      "metadata": {
        "id": "__W8lRYlIkSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solo porque DeepXDE utiliza por defecto TensorFlow\n",
        "# lo importaremos, solo para este ejemplo!\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "5YMrWMwD_keT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros\n",
        "dim = 2\n",
        "\n",
        "precision_train = 15\n",
        "precision_test = 30\n",
        "\n",
        "hx_train = 1 / precision_train\n",
        "nx_train = int(1 / hx_train)\n",
        "\n",
        "hx_test = 1 / precision_test\n",
        "nx_test = int(1 / hx_test)\n",
        "\n",
        "# Pesos de las pérdidas\n",
        "weight_inner = 1\n",
        "weight_outer = 1\n",
        "weight_known = 1\n",
        "\n",
        "iterations = 10000\n",
        "learning_rate = 1e-3\n",
        "num_dense_layers = 3\n",
        "num_dense_nodes = 350\n",
        "activation = \"tanh\""
      ],
      "metadata": {
        "id": "s6JJUryY_IhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros de la geometría\n",
        "n = 1\n",
        "length = 1\n",
        "R = 1 / 4\n",
        "\n",
        "# Creación de la geometría\n",
        "outer = dde.geometry.Rectangle([-length / 2, -length / 2], [length / 2, length / 2])\n",
        "inner = dde.geometry.Disk([0, 0], R)\n",
        "\n",
        "# Fronteras de la geometría\n",
        "def boundary_outer(x, on_boundary):\n",
        "    return on_boundary and outer.on_boundary(x)\n",
        "\n",
        "\n",
        "def boundary_inner(x, on_boundary):\n",
        "    return on_boundary and inner.on_boundary(x)\n",
        "\n",
        "\n",
        "def boundary(_, on_boundary):\n",
        "    return on_boundary\n",
        "\n",
        "# Geometry as a difference\n",
        "geom = outer - inner"
      ],
      "metadata": {
        "id": "iQYnh8RC_S7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Máscara del dominio\n",
        "def mask(x):\n",
        "    return (x[0] < 0)*(x[1] < 0)\n",
        "\n",
        "\n",
        "# Número de puntos considerados\n",
        "meas_ratio = 1/4\n",
        "sample_points = 20\n",
        "\n",
        "points_int = geom.random_points(sample_points, ).T\n",
        "points_bound = geom.random_boundary_points(1000).T\n",
        "\n",
        "# Create the masked array\n",
        "ma = mask(points_int)\n",
        "\n",
        "masked_points = points_int.T[ma].T\n",
        "obt_points = int(len(masked_points.T))\n",
        "print(\"Número de puntos efectivo en el dominio: {}\".format(obt_points))"
      ],
      "metadata": {
        "id": "Jip6dFes_bLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico con Plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=masked_points[0], y=masked_points[1], mode='markers', name='Puntos de solución conocida', marker=dict(color='blue', opacity=0.9))\n",
        "    )\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=points_bound[0], y=points_bound[1], mode='markers', name='Puntos de frontera', marker=dict(color='red', opacity=0.6))\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Puntos de dominio: {len(masked_points[0])}\",\n",
        "    height=700,\n",
        "    width=900)"
      ],
      "metadata": {
        "id": "AiX7qbTK_4Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función conocida\n",
        "def func_known(x):\n",
        "    return np.sin(x[:,0:1]**2 + x[:,1:2]**2)\n",
        "\n",
        "known_points = masked_points\n",
        "known_u = func_known(masked_points.T)\n",
        "\n",
        "# Establecer los puntos conocidos\n",
        "observe_u = dde.icbc.PointSetBC(known_points.T, known_u)\n",
        "\n",
        "# Se deja como una \"condición de borde\"\n",
        "bcs = [observe_u]"
      ],
      "metadata": {
        "id": "ra_JBudtAv6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz que representa al Laplaciano\n",
        "def A(x1, x2):\n",
        "    a11 = 1. + x1*0 + x2*0\n",
        "    a12 = 0. + x1*0 + x2*0\n",
        "    a21 = 0. + x1*0 + x2*0\n",
        "    a22 = 1. + x1*0 + x2*0\n",
        "\n",
        "    return [\n",
        "        [a11, a12],\n",
        "        [a21, a22]\n",
        "    ]\n",
        "\n",
        "# Lado derecho de la ecuación\n",
        "def f(x, y):\n",
        "    return -4*(-tf.cos(x[:,0:1]**2 + x[:,1:2]**2) + (x[:,0:1]**2 + x[:,1:2]**2)*tf.sin(x[:,0:1]**2 + x[:,1:2]**2))"
      ],
      "metadata": {
        "id": "-DykgKZrA8EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDP\n",
        "def pde(x, y):\n",
        "    Dy = [dde.grad.jacobian(y, x, j=j) for j in range(dim)]\n",
        "    D2y = []\n",
        "    for i in range(dim):\n",
        "        D2y.append([dde.grad.hessian(y, x, i=i, j=j) for j in range(dim)])\n",
        "\n",
        "    A_eval = A(x[:,0:1], x[:,1:2])\n",
        "\n",
        "    result = 0\n",
        "\n",
        "    for i in range(dim):\n",
        "        for j in range(dim):\n",
        "            result += A_eval[i][j]*D2y[i][j]\n",
        "\n",
        "    return result - f(x, y)"
      ],
      "metadata": {
        "id": "okhReUcTA_fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamos la red neuronal y creamos el modelo de EDP\n",
        "\n",
        "data = dde.data.PDE(\n",
        "    geom,\n",
        "    pde,\n",
        "    bcs,\n",
        "    num_domain=nx_train**2,\n",
        "    num_boundary=16 * nx_train\n",
        ")\n",
        "\n",
        "net = dde.nn.FNN(\n",
        "    [dim] + [num_dense_nodes] * num_dense_layers + [1], activation, \"Glorot uniform\"\n",
        ")\n",
        "\n",
        "model = dde.Model(data, net)"
      ],
      "metadata": {
        "id": "-FplEQcDBajq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "\n",
        "loss_weights = [1, weight_known] # Seteamos como 1 el peso de la colocación\n",
        "\n",
        "model.compile(\n",
        "    \"adam\", lr=learning_rate, loss_weights=loss_weights\n",
        ")\n",
        "\n",
        "losshistory, train_state = model.train(iterations=iterations)\n",
        "dde.saveplot(losshistory, train_state, issave=True, isplot=True)"
      ],
      "metadata": {
        "id": "Qw_TxCqiBjmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías necesarias para este gráfico\n",
        "import matplotlib.tri as tri\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.cm as cm\n",
        "from functools import reduce\n",
        "\n",
        "# Números de puntos para el gráfico\n",
        "Nx = 60\n",
        "Ny = Nx\n",
        "\n",
        "# Puntos de grilla\n",
        "xmin, xmax, ymin, ymax = [-length / 2, length / 2, -length / 2, length / 2]\n",
        "\n",
        "# Predicción del modelo\n",
        "x, y = np.linspace(xmin, xmax, Nx), np.linspace(ymin, ymax, Nx)\n",
        "arrays = [np.vstack((x,np.ones(Nx)*y[i])) for i in range(Ny)]\n",
        "X = np.hstack(arrays)\n",
        "u = model.predict(X.T)\n",
        "\n",
        "# Máscaras y triangulaciones\n",
        "dom_mask = geom.inside(X.T)\n",
        "\n",
        "X_dom = X.T[dom_mask]\n",
        "x_dom, y_dom = X_dom[:,0], X_dom[:,1]\n",
        "u_dom = u[dom_mask].reshape(len(X_dom[:,0]))\n",
        "\n",
        "exact_dom = func_known(X.T)[dom_mask].flatten()\n",
        "\n",
        "triang = tri.Triangulation(x_dom, y_dom)\n",
        "x2 = x_dom[triang.triangles].mean(axis=1)\n",
        "y2 = y_dom[triang.triangles].mean(axis=1)\n",
        "\n",
        "dom_mask2 = geom.inside((np.vstack((x2, y2)).T))\n",
        "\n",
        "triang.set_mask(~dom_mask2)\n",
        "\n",
        "# Gráfico\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18,5))\n",
        "\n",
        "c1 = ax[0].tricontourf(triang, u_dom, levels=20)\n",
        "ax[0].set_xlabel(\"x\")\n",
        "ax[0].set_ylabel(\"y\")\n",
        "ax[0].set_title(\"PINN\")\n",
        "\n",
        "divider = make_axes_locatable(ax[0])\n",
        "cax = divider.append_axes('right', size='3%', pad=0.02)\n",
        "fig.colorbar(c1, cax=cax, orientation='vertical')\n",
        "\n",
        "c2 = ax[1].tricontourf(triang, exact_dom, levels=20)\n",
        "ax[1].set_xlabel(\"x\")\n",
        "#ax[1].set_ylabel(\"y\")\n",
        "ax[1].set_title(\"Exacta\")\n",
        "\n",
        "divider = make_axes_locatable(ax[1])\n",
        "cax = divider.append_axes('right', size='3%', pad=0.02)\n",
        "fig.colorbar(c2, cax=cax, orientation='vertical')\n",
        "\n",
        "c3 = ax[2].tricontourf(triang, np.abs(u_dom-exact_dom), levels=20)\n",
        "ax[2].scatter(known_points[0], known_points[1], s=10., c=\"red\")\n",
        "ax[2].set_xlabel(\"x\")\n",
        "ax[2].set_title(\"Error absoluto\")\n",
        "\n",
        "divider = make_axes_locatable(ax[2])\n",
        "cax = divider.append_axes('right', size='3%', pad=0.02)\n",
        "fig.colorbar(c3, cax=cax, orientation='vertical')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8ia052uXBxOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico con Plotly\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=3,\n",
        "    subplot_titles=(\"PINN\", \"Exacta\", \"Error absoluto\"),\n",
        "    specs=[[{\"type\": \"surface\"}, {\"type\": \"surface\"}, {\"type\": \"surface\"}]])\n",
        "\n",
        "c1 = go.Mesh3d(x=x_dom, y=y_dom, z=u_dom, intensity=u_dom, name='PINN', showscale=False)\n",
        "\n",
        "c2 = go.Mesh3d(x=x_dom, y=y_dom, z=exact_dom, intensity=exact_dom, name='Exacta', showscale=False)\n",
        "\n",
        "c3 = go.Mesh3d(x=x_dom, y=y_dom, z=np.abs(u_dom-exact_dom), intensity=np.abs(u_dom-exact_dom), name='Error absoluto', showscale=True)\n",
        "\n",
        "fig.add_trace(c1, row=1, col=1)\n",
        "fig.add_trace(c2, row=1, col=2)\n",
        "fig.add_trace(c3, row=1, col=3)\n",
        "\n",
        "fig"
      ],
      "metadata": {
        "id": "f0l1szEDcMy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 3: DeepONets**"
      ],
      "metadata": {
        "id": "c131VHJ-YR_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veremos una extensión de las PINNs, que son las DeepONets (Deep Operator Networks). Para ello utilizaremos DeepXDE, que implementa las DeepONets tal como el [artículo original](https://arxiv.org/abs/1910.03193)."
      ],
      "metadata": {
        "id": "k4JxIxeWIY6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicaremos las DeepONets al problema de aprender el operador $G: C([0, 1]) \\times [0, 1] \\to \\mathbb{R}$ definido por\n",
        "\n",
        "$$ G(u, x) = \\int_0^x u(s) ds $$"
      ],
      "metadata": {
        "id": "L2kZ8mrOOQAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaremos otras librerías solo para este ejemplo\n",
        "import scipy.stats as stats\n",
        "from scipy.integrate import cumulative_trapezoid\n",
        "from sklearn.gaussian_process.kernels import RBF"
      ],
      "metadata": {
        "id": "IHWLtZsROwFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora debemos generar datos para poder entrenar la red, es decir, necesitamos funciones $u \\in C([0,1])$ dadas para poder crear otras funciones $v$ definidas por\n",
        "\n",
        "$$ v(x) = G(u,y) = \\int_0^x u(s) ds $$\n",
        "\n",
        "En otras palabras, necesitamos la función a integrar y el valor de la integral en cada punto. ¿Y cómo podemos generar muchas funciones de manera rápida? La solución más eficiente y que no tiene un sesgo significativo respecto a la forma de la función es samplear una función desde un proceso gaussiano.\n",
        "\n",
        "Esto es lo siguiente, si tengo una discretización $X = \\{ x_i \\}_{i=1}^N$ del intervalo $[0, 1]$, entonces una función $u$ es sampleada desde un proceso gaussiano representado por los $X$ si\n",
        "\n",
        "$$ u(X) \\sim N( 0_{N}, k(X, X)) $$\n",
        "\n",
        "Donde $k$ es lo que se llama una función *kernel*, en este caso $k: [0, 1] \\times [0, 1] \\to \\mathbb{R}$ dada por\n",
        "\n",
        "$$ k(x, y) = \\text{exp} (- |x-y|^2/(2 \\sigma^2)) $$\n",
        "\n",
        "Que se denota por *kernel* gaussiano o RBF. Por tanto $k(X, X)$ actúa como matriz de covarianzas\n",
        "\n",
        "$$ k(X, X)_{ij} = k(x_i, x_j) $$\n",
        "\n",
        "Con esto veamos como samplear funciones aleatorias con Python."
      ],
      "metadata": {
        "id": "Pu7GkeajPPVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampleo desde un proceso gaussiano\n",
        "Npoints = 100  # Cantidad de puntos en cada trayectoria\n",
        "Ntraj_train = 150  # Cantidad de trayectorias de entrenamiento\n",
        "Ntraj_test = 300  # Cantidad de trayectorias de testeo\n",
        "\n",
        "# Puntos a samplear en [0, 1]\n",
        "x0, xf = 0, 1\n",
        "xdim = 1\n",
        "\n",
        "# Arreglo sin expandir\n",
        "x = np.linspace(0, 1, Npoints)\n",
        "\n",
        "# Arreglo expandido\n",
        "X = np.expand_dims(np.linspace(x0, xf, Npoints), xdim)"
      ],
      "metadata": {
        "id": "N54tFpE5POrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos el kernel gaussiano creado por Sklearn y creamos la matriz de covarianzas."
      ],
      "metadata": {
        "id": "Ss2HvRmWjoly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kernel gaussiano\n",
        "kernel = RBF(0.25)\n",
        "\n",
        "# Matriz de covarianzas dada por el kernel\n",
        "Sigma = kernel.__call__(X, X)"
      ],
      "metadata": {
        "id": "Wh0YEIPJiWKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos como se ve el kernel en el intervalo $[0,1]$."
      ],
      "metadata": {
        "id": "iu8adiiZjvVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Punto fijo con respecto a que calcular el kernel, solo para visualizar\n",
        "center = 0.5\n",
        "\n",
        "# Imagen del kernel a través del punto fijo y todo el intervalo [0, 1]\n",
        "ker_img = kernel.__call__(np.array([[center]]), X).reshape(len(x))\n",
        "\n",
        "# Gráfico con Plotly\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=x, y=ker_img, mode='lines'))\n",
        "fig.update_layout(\n",
        "    title=f\"Visualización del kernel con un punto fijo\",\n",
        "    xaxis_title=\"x\",\n",
        "    yaxis_title=r\"$k({}, x)$\".format(center))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FGfdctI4iycG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos como se ve la matriz de covarianzas."
      ],
      "metadata": {
        "id": "KhXff9GVkSHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico\n",
        "X1, X2 = np.meshgrid(x, x)\n",
        "\n",
        "fig = go.Figure(data=go.Contour(z=Sigma, x=x, y=x))\n",
        "fig.update_layout(\n",
        "    title=r\"$k(x,x)$\",\n",
        "    xaxis_title=\"x\",\n",
        "    yaxis_title=\"x\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "XE-7Bs2vis2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora generaremos las funciones (o trayectorias) sampleadas desde un proceso gaussiano."
      ],
      "metadata": {
        "id": "ZHu6C6z3k5LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampleo desde una normal multivariada para simular el proceso\n",
        "\n",
        "# Entrenamiento\n",
        "gpr_train = np.random.multivariate_normal(\n",
        "    mean=np.zeros(Npoints),\n",
        "    cov=Sigma,\n",
        "    size=Ntraj_train)\n",
        "\n",
        "# Testeo\n",
        "gpr_test = np.random.multivariate_normal(\n",
        "    mean=np.zeros(Npoints),\n",
        "    cov=Sigma,\n",
        "    size=Ntraj_test)"
      ],
      "metadata": {
        "id": "ntXp0lzEKpGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos una de las trayectorias sampleadas."
      ],
      "metadata": {
        "id": "_Hbio4-Uk_PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico con Plotly\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=x, y=gpr_train[0], mode='lines', line=dict(dash='dashdot')))\n",
        "fig.update_layout(\n",
        "    title=f\"Visualización de una trayectoria sampleada\",\n",
        "    xaxis_title=\"x\",\n",
        "    yaxis_title=\"y\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2eHXS4-WmYGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora graficamos todas las trayectorias que se usarán para entrenar a la red."
      ],
      "metadata": {
        "id": "Lms5cZZOINeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico\n",
        "fig = go.Figure()\n",
        "for i in range(Ntraj_train):\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=x, y=gpr_train[i], mode='lines', line=dict(dash='dashdot'), name=f'Trayectoria {i+1}'))\n",
        "fig.update_layout(\n",
        "    title=f\"Visualización de las {Ntraj_train} trayectorias sampleadas\",\n",
        "    xaxis_title=\"x\",\n",
        "    yaxis_title=\"y\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "oTW1WLusKyKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después calculamos las integrales en todos los puntos de la discretización, para todas las trayectorias."
      ],
      "metadata": {
        "id": "y84zC2ffIT7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trayectorias integradas, entrenamiento\n",
        "int_traj_train = cumulative_trapezoid(gpr_train, x, axis=1, initial=0)\n",
        "\n",
        "# Trayectorias integradas, testeo\n",
        "int_traj_test = cumulative_trapezoid(gpr_test, x, axis=1, initial=0)"
      ],
      "metadata": {
        "id": "XQKZVQFoiBaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset para entrenar\n",
        "X_train = (gpr_train, X)\n",
        "y_train = int_traj_train\n",
        "\n",
        "# Dataset para testear\n",
        "X_test = (gpr_test, X)\n",
        "y_test = int_traj_test\n",
        "\n",
        "# Juntamos todos los dataset en un formato que DeepXDE dispone para las DeepONets\n",
        "data = dde.data.TripleCartesianProd(\n",
        "    X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test\n",
        ")"
      ],
      "metadata": {
        "id": "JnQi0crMWy5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDyTBoLNEW_z"
      },
      "outputs": [],
      "source": [
        "# Armamos la red\n",
        "\n",
        "# Dimensión para la branch net\n",
        "n_branch = 20\n",
        "\n",
        "# Dimensión para la trunk net\n",
        "n_trunk = 20\n",
        "\n",
        "# Red con Tanh e iniciación Glorot\n",
        "net = dde.nn.DeepONetCartesianProd(\n",
        "    [Npoints, n_branch, n_branch],\n",
        "    [xdim, n_trunk, n_trunk],\n",
        "    \"tanh\",\n",
        "    \"Glorot normal\",\n",
        ")\n",
        "\n",
        "# Modelo\n",
        "model = dde.Model(data, net)\n",
        "\n",
        "# Compilación y entrenamiento\n",
        "model.compile(\"adam\", lr=0.001, metrics=[\"mean l2 relative error\"])\n",
        "losshistory, train_state = model.train(iterations=25000)\n",
        "\n",
        "# Plot the loss trajectory\n",
        "dde.utils.plot_loss_history(losshistory)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora testeamos con funciones coseno de distinta frecuencia."
      ],
      "metadata": {
        "id": "Rw2rcHshQEES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testeamos con una función conocida\n",
        "f = lambda x, w: np.cos(w*x)\n",
        "f_int = lambda x, w: np.sin(w*x)/w"
      ],
      "metadata": {
        "id": "iDjTA7FpQvly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de funciones a testear\n",
        "n_test = 5\n",
        "fun_test = np.zeros((n_test, Npoints))\n",
        "fun_test_int = np.zeros((n_test, Npoints))\n",
        "\n",
        "# Frecuencias a probar\n",
        "omegas = np.linspace(1, 2*np.pi, n_test)\n",
        "\n",
        "# Se calcula cada una\n",
        "for i in range(n_test):\n",
        "    fun_test[i] = f(x, omegas[i])\n",
        "    fun_test_int[i] = f_int(x, omegas[i])"
      ],
      "metadata": {
        "id": "-86_SGUxQL5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arreglo disminuido para poder evaluar\n",
        "x_arr = np.expand_dims(x, axis=-1)\n",
        "\n",
        "# Predicción del modelo\n",
        "y_pred = model.predict((fun_test, x_arr)).reshape((n_test, Npoints))"
      ],
      "metadata": {
        "id": "7vZDVIvrTPrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico\n",
        "fig = go.Figure()\n",
        "for i in range(n_test):\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=x,\n",
        "                   y=y_pred[i],\n",
        "                   mode='lines',\n",
        "                   name=r\"NN omega = {}\".format(round(omegas[i], 2))))\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=x,\n",
        "                   y=fun_test_int[i],\n",
        "                   mode='lines',\n",
        "                   name=r\"Real omega = {}\".format(round(omegas[i], 2))))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f\"Visualización de las predicciones de la red\",\n",
        "    xaxis_title=\"x\",\n",
        "    yaxis_title=\"y\")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "NFJtAIpDSDPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parte 3: Generative Adversarial Networks**"
      ],
      "metadata": {
        "id": "a6fcs6YOe5mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de hiperparámetros\n",
        "latent_dim = 100  # Dimensión del espacio latente\n",
        "data_dim = 1     # Dimensión de los datos (Gaussiana 1D)\n",
        "batch_size = 64\n",
        "num_epochs = 5000\n",
        "learning_rate = 1e-3\n",
        "n_neurons = 64\n",
        "\n",
        "# Definición del Generador\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, data_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, n_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_neurons, n_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_neurons, data_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "# Definición del Discriminador\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, data_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(data_dim, n_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_neurons, n_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_neurons, 1),\n",
        "            nn.Sigmoid()  # Predicción de probabilidad\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Inicialización de los modelos\n",
        "generator = Generator(latent_dim, data_dim)\n",
        "discriminator = Discriminator(data_dim)\n",
        "\n",
        "# Optimizadores\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Función para generar datos reales (distribución Gaussiana)\n",
        "def sample_real_data(batch_size):\n",
        "    return torch.tensor(np.random.normal(0, 1, (batch_size, data_dim)), dtype=torch.float32)\n",
        "\n",
        "# Función para generar ruido latente\n",
        "def sample_latent_noise(batch_size, latent_dim):\n",
        "    return torch.randn(batch_size, latent_dim)\n",
        "\n",
        "# Data real, para comparar histogramas\n",
        "real_data_sample = sample_real_data(1000).numpy().flatten()\n",
        "\n",
        "# Configuración de la animación\n",
        "frames = []\n",
        "\n",
        "# Lista para los datos generados\n",
        "generated_data_list = []\n",
        "\n",
        "# Entrenamiento de la GAN\n",
        "for epoch in range(num_epochs):\n",
        "    # Entrenamiento del Discriminador\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    # Datos reales\n",
        "    real_data = sample_real_data(batch_size)\n",
        "    real_labels = torch.ones(batch_size, 1)\n",
        "\n",
        "    # Datos generados\n",
        "    latent_noise = sample_latent_noise(batch_size, latent_dim)\n",
        "    fake_data = generator(latent_noise)\n",
        "    fake_labels = torch.zeros(batch_size, 1)\n",
        "\n",
        "    # Pérdida del Discriminador\n",
        "    real_loss = nn.BCELoss()(discriminator(real_data), real_labels)\n",
        "    fake_loss = nn.BCELoss()(discriminator(fake_data.detach()), fake_labels)\n",
        "    d_loss = real_loss + fake_loss\n",
        "\n",
        "    d_loss.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    # Entrenamiento del Generador\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    # Datos generados (sin detach)\n",
        "    fake_data = generator(latent_noise)\n",
        "    fake_labels = torch.ones(batch_size, 1)  # El Generador quiere engañar al Discriminador\n",
        "\n",
        "    # Pérdida del Generador\n",
        "    g_loss = nn.BCELoss()(discriminator(fake_data), fake_labels)\n",
        "\n",
        "    g_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    # Impresión de progreso\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}] | D_loss: {d_loss.item():.4f} | G_loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Capturar datos para la animación\n",
        "    if epoch % 50 == 0:\n",
        "        with torch.no_grad():\n",
        "            latent_noise = sample_latent_noise(1000, latent_dim)\n",
        "            generated_data = generator(latent_noise).numpy().flatten()\n",
        "\n",
        "            # Crear un frame para la animación\n",
        "            frame = go.Frame(\n",
        "                data=[\n",
        "                    go.Histogram(x=generated_data, nbinsx=50, opacity=0.7, histnorm='probability density', name=\"Datos generados\"),\n",
        "                    go.Histogram(x=real_data_sample, nbinsx=50, opacity=0.7, histnorm='probability density', name=\"Datos reales\")\n",
        "                ],\n",
        "                name=f\"Epoch {epoch}\"\n",
        "            )\n",
        "            frames.append(frame)\n",
        "            generated_data_list.append(generated_data)\n",
        "\n",
        "# Crear la figura de animación\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Histogram(x=[], nbinsx=50, opacity=0.7, histnorm='probability density', name=\"Datos generados\"),\n",
        "        go.Histogram(x=real_data_sample, nbinsx=50, opacity=0.7, histnorm='probability density', name=\"Datos reales\")\n",
        "    ],\n",
        "    layout=go.Layout(\n",
        "        title=\"Evolución de la distribución generada vs. datos reales\",\n",
        "        xaxis=dict(title=\"Valor\"),\n",
        "        yaxis=dict(title=\"Frecuencia\"),\n",
        "        updatemenus=[dict(\n",
        "            type=\"buttons\",\n",
        "            buttons=[dict(label=\"Reproducir\", method=\"animate\", args=[None])]\n",
        "        )]\n",
        "    ),\n",
        "    frames=frames\n",
        ")\n",
        "\n",
        "\n",
        "# Mostrar la animación\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gRPlk4F_RV7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de los datos generados\n",
        "with torch.no_grad():\n",
        "    latent_noise = sample_latent_noise(5000, latent_dim)\n",
        "    generated_data = generator(latent_noise).numpy().squeeze()\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Histogram(x=generated_data, histnorm='probability density', name='Datos generados'))\n",
        "fig.add_trace(go.Histogram(x=real_data_sample, histnorm='probability density', name='Datos reales'))\n",
        "\n",
        "fig.update_traces(opacity=0.7)\n",
        "fig.update_layout(\n",
        "    title=\"Distribución de datos generados vs. datos reales\",\n",
        "    xaxis_title=\"Valor\",\n",
        "    yaxis_title=\"Frecuencia\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "YWJKbq9FS-0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Podemos hacerle un test de normalidad a las muestras! Esto es, hacer un test de hipótesis para poder ver que tan probable es que la muestra provenga de una gaussiana estándar. Esto se puede hacer con el test de Shapiro-Wilk de normalidad, en donde, si su estadístico se acerca a 1, entonces no se rechaza la hipótesis nula, que es que los datos no provengan de una normal estándar."
      ],
      "metadata": {
        "id": "tPORFd8wbI16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de normalidad\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "# Testeamos en el resultado final\n",
        "shapiro(generated_data)"
      ],
      "metadata": {
        "id": "yX-fokUranxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y podemos ver cómo evoluciona el estadístico en cada una de las iteraciones."
      ],
      "metadata": {
        "id": "UtgLMDMHeLzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico con Plotly\n",
        "statistics = []\n",
        "\n",
        "for i in range(len(generated_data_list)):\n",
        "    statistics.append(shapiro(generated_data_list[i])[0])\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=np.arange(1, num_epochs+1, 50), y=statistics, mode='lines'))\n",
        "fig.update_layout(\n",
        "    title=f\"Evolución del estadístico de Shapiro-Wilk\",\n",
        "    xaxis_title=\"Iteración\",\n",
        "    yaxis_title=\"Estadístico\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hufDKTKmeQuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15cea7c2-08e9-4756-bd2a-bf3a206a53dc"
      },
      "source": [
        "## **Parte 4: Generando Dígitos de MNIST usando GANs**\n",
        "\n",
        "Intentaremos generar dígitos \"sintéticos\" usando una GAN muy simple. Para ello, consideraremos el formato de dígitos entre 0 y 9 del dataset MINST."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar Librerías Necesarias"
      ],
      "metadata": {
        "id": "dO2HE9vhQDYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "metadata": {
        "id": "j3PLQtCFb0xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "832a09ee-a365-4f10-a538-2712eb4c933d"
      },
      "outputs": [],
      "source": [
        "# Librerías extras para este ejemplo\n",
        "import math\n",
        "import pickle as pkl\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39970055-91f1-4679-b47a-792fab843d7e"
      },
      "source": [
        "## Cargamos los datos del MNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "batch_size = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Preprocesamiento\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)"
      ],
      "metadata": {
        "id": "_132nUjeYsJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construimos el DataLoader que usaremos para entrenar nuestra GAN"
      ],
      "metadata": {
        "id": "x0WfIGEoQUm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Los loader de training y los de test\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "dZsLxITRZTEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que nos da resultados consistentes:"
      ],
      "metadata": {
        "id": "xt8xIG3BQbdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "689af3ec-8bdf-44ee-afd3-041ad9845036"
      },
      "outputs": [],
      "source": [
        "# Vemos el \"primer\" batch disponible:\n",
        "image_batch = next(iter(train_loader))\n",
        "print(len(image_batch), type(image_batch))\n",
        "print(image_batch[0].shape)\n",
        "print(image_batch[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cdbfe38-af0d-4024-bd3d-9b91a576176e"
      },
      "outputs": [],
      "source": [
        "## ----------------------------------------------------------------------------\n",
        "## Visualización de un Batch\n",
        "## ----------------------------------------------------------------------------\n",
        "\n",
        "def display_images(images, n_cols=4, figsize=(12, 6)):\n",
        "    \"\"\"\n",
        "    Función útil para mostrar un batch de imágenes en una grilla.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    images: Tensor\n",
        "            tensor of shape (batch_size, channel, height, width)\n",
        "            containing images to be displayed\n",
        "    n_cols: int\n",
        "            number of columns in the grid\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    plt.style.use('ggplot')\n",
        "    n_images = len(images)\n",
        "    n_rows = math.ceil(n_images / n_cols)\n",
        "    plt.figure(figsize=figsize)\n",
        "    for idx in range(n_images):\n",
        "        ax = plt.subplot(n_rows, n_cols, idx+1)\n",
        "        image = images[idx]\n",
        "        # make dims H x W x C\n",
        "        image = image.permute(1, 2, 0)\n",
        "        cmap = 'gray' if image.shape[2] == 1 else plt.cm.viridis\n",
        "        ax.imshow(image, cmap=cmap)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_images(images=image_batch[0], n_cols=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recordamos el problema de clasificación en MNIST"
      ],
      "metadata": {
        "id": "MritnTLifGRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una CNN simple para clasificar las clases del MNIST\n",
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(384, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxpool(self.relu(self.conv1(x)))\n",
        "        x = self.maxpool(self.relu(self.conv2(x)))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Rcmw8Sfje-n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_classif = 0.01\n",
        "n_epochs_classif = 10\n",
        "\n",
        "classifier = MNISTClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate_classif)\n",
        "\n",
        "def train_epoch(classifier, train_loader, criterion, optimizer):\n",
        "    classifier.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = classifier(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    return running_loss / len(train_loader), 100. * correct / total\n",
        "\n",
        "def evaluate(classifier, test_loader):\n",
        "    classifier.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = classifier(data)\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    return 100. * correct / total\n",
        "\n",
        "# Training loop\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(n_epochs_classif):\n",
        "    train_loss, train_acc = train_epoch(classifier, train_loader, criterion, optimizer)\n",
        "    test_acc = evaluate(classifier, test_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}/{n_epochs_classif}')\n",
        "    print(f'Training Loss: {train_loss:.4f}')\n",
        "    print(f'Training Accuracy: {train_acc:.2f}%')\n",
        "    print(f'Test Accuracy: {test_acc:.2f}%')\n",
        "    print('-' * 50)\n",
        "\n",
        "# Guardamos el clasificador\n",
        "torch.save(classifier.state_dict(), 'mnist_classifier.pth')\n",
        "\n",
        "# Graficar las curvas\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train')\n",
        "plt.plot(test_accuracies, label='Test')\n",
        "plt.title('Classification Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VW2uVjc4XXiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el Clasificador Pre-Entrenado\n",
        "classifier = MNISTClassifier()\n",
        "classifier.load_state_dict(torch.load('mnist_classifier.pth'))\n",
        "classifier.eval()"
      ],
      "metadata": {
        "id": "dThEixS-enU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos cómo le va a nuestro modelo entrenado sobre un batch de datos"
      ],
      "metadata": {
        "id": "ezsQIBEEfWyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos un batch de imágenes\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "classifier = classifier.to(device)\n",
        "# Hacemos predicciones\n",
        "with torch.no_grad():\n",
        "    outputs = classifier(images)\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    _, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "# Visualizamos las imágenes y las predicciones\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(10):  # Mostramos las primeras 10 imágenes\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    image = images[i].cpu().numpy().squeeze()\n",
        "    true_label = labels[i].item()\n",
        "    pred_label = predicted[i].item()\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f'True: {true_label}\\nPred: {pred_label}')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9yN5oaB7elo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genial! Pero no nos interesa clasificar estos datos, sino poder **generarlos**..."
      ],
      "metadata": {
        "id": "TURRW8wIfeQ7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2f47858-06cf-4e7d-a204-7ed33fda9b33"
      },
      "source": [
        "## Definición de la GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3628845f-5c52-4848-8ba2-54ab6f639386"
      },
      "source": [
        "### Discriminator Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos un discriminador estándar... Esencialmente un \"clasificador\" de imágenes."
      ],
      "metadata": {
        "id": "9CZu9SlTQ2l3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e73a0e41-af62-4607-82aa-d1f8822efc7c"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # Usamos una FFNN con Leaky-ReLUs y Dropout.\n",
        "        self.fc1 = nn.Linear(in_features=in_features, out_features=128)\n",
        "        self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
        "        self.leaky_relu2 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=32)\n",
        "        self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.fc4 = nn.Linear(in_features=32, out_features=out_features)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten a la entrada\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.view(batch_size, -1)\n",
        "        # Feed forward\n",
        "        x = self.fc1(x)\n",
        "        x = self.leaky_relu1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.leaky_relu2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.leaky_relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        logit_out = self.fc4(x)\n",
        "\n",
        "        return logit_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0f606cf-e9e3-4821-94ae-abf1d7e5c99a"
      },
      "source": [
        "### Generator Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestra red generadora debe ser capaz de \"crear\" imágenes en el formato deseado, a partir de ruido en una dimensión menor"
      ],
      "metadata": {
        "id": "ztUjsrNrRSIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "727408f5-76b9-4ef1-8755-029b7d96abeb"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Generator, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # El Generator va a up-samplear el input, produciendo datos listos para el discriminador\n",
        "        self.fc1 = nn.Linear(in_features=in_features, out_features=32)\n",
        "        self.relu1 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.fc2 = nn.Linear(in_features=32, out_features=64)\n",
        "        self.relu2 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.fc3 = nn.Linear(in_features=64, out_features=128)\n",
        "        self.relu3 = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.fc4 = nn.Linear(in_features=128, out_features=out_features)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feed forward\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        tanh_out = self.tanh(x)\n",
        "\n",
        "        return tanh_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264df085-aa20-4686-a992-57c603a9c224"
      },
      "source": [
        "## Definición de las Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6938e67-2de2-424b-8d23-339302dde4ed"
      },
      "outputs": [],
      "source": [
        "def real_loss(predicted_outputs, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Función para calcular la loss cuando las muestras vienen del dataset real\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    predicted_outputs: Tensor\n",
        "                       predicted logits\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    real_loss: int\n",
        "    \"\"\"\n",
        "    batch_size = predicted_outputs.shape[0]\n",
        "    # Los Targets se definen como 1, porque se espera que la predicción sea\n",
        "    # 1 (o cercano a 1), ya que las muestras vienen del dataset real.\n",
        "    targets = torch.ones(batch_size).to(device)\n",
        "    real_loss = loss_fn(predicted_outputs.squeeze(), targets)\n",
        "\n",
        "    return real_loss\n",
        "\n",
        "\n",
        "def fake_loss(predicted_outputs, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Función para calcular la loss cuando las samples son las \"generadas\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    predicted_outputs: Tensor\n",
        "                       predicted logits\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    fake_loss: int\n",
        "    \"\"\"\n",
        "    batch_size = predicted_outputs.shape[0]\n",
        "    # Los Targets se definen como 0, porque se espera que la predicción sea\n",
        "    # 0 (o cercano a 0), ya que las muestras son falsas.\n",
        "    targets = torch.zeros(batch_size).to(device)\n",
        "    fake_loss = loss_fn(predicted_outputs.squeeze(), targets)\n",
        "\n",
        "    return fake_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b7f1066-48b2-498c-9889-c25a608d0fbe"
      },
      "source": [
        "## Entrenando nuestras redes\n",
        "El Discriminador y Generador se entrenan en conjunto, pero cada uno requiere su propio optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc3a0e7f-79f2-4b29-8b8e-be64ffd79912"
      },
      "outputs": [],
      "source": [
        "#Visualización de un vector en el espacio latente (de donde samplearemos)\n",
        "z_size = 100\n",
        "z = np.random.uniform(-1, 1, size=(16, z_size))\n",
        "plt.imshow(z, cmap='gray')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el Loop de Entrenamiento:"
      ],
      "metadata": {
        "id": "T7oaQ3EYbLiJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7721b017-4c95-43bb-8f47-422851c3d5af"
      },
      "outputs": [],
      "source": [
        "def train_minst_gan(d, g, d_optim, g_optim, loss_fn, dl, n_epochs, device, verbose=False):\n",
        "    print(f'Training on [{device}]...')\n",
        "\n",
        "    # Generate a batch (say 16) of latent image vector (z) of fixed size\n",
        "    # (say 100 pix) to be as input to the Generator after each epoch of\n",
        "    # training to generate a fake image. We'll visualise these fake images\n",
        "    # to get a sense how generator improves as training progresses\n",
        "    z_size = 100\n",
        "    fixed_z = np.random.uniform(-1, 1, size=(16, z_size))\n",
        "    fixed_z = torch.from_numpy(fixed_z).float().to(device)\n",
        "    fixed_samples = []\n",
        "    d_losses = []\n",
        "    g_losses = []\n",
        "\n",
        "\n",
        "    # Move discriminator and generator to available device\n",
        "    d = d.to(device)\n",
        "    g = g.to(device)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}]:')\n",
        "        # Switch the training mode on\n",
        "        d.train()\n",
        "        g.train()\n",
        "        d_running_batch_loss = 0\n",
        "        g_running_batch_loss = 0\n",
        "        for curr_batch, (real_images, _) in enumerate(dl):\n",
        "            # Move input batch to available device\n",
        "            real_images = real_images.to(device)\n",
        "\n",
        "            ## ----------------------------------------------------------------\n",
        "            ## Train discriminator using real and then fake MNIST images,\n",
        "            ## then compute the total-loss and back-propogate the total-loss\n",
        "            ## ----------------------------------------------------------------\n",
        "\n",
        "            # Reset gradients\n",
        "            d_optim.zero_grad()\n",
        "\n",
        "            # Real MNIST images\n",
        "            # Convert real_images value range of 0 to 1 to -1 to 1\n",
        "            # this is required because latter discriminator would be required\n",
        "            # to consume generator's 'tanh' output which is of range -1 to 1\n",
        "            real_images = (real_images * 2) - 1\n",
        "            d_real_logits_out = d(real_images)\n",
        "            d_real_loss = real_loss(d_real_logits_out, loss_fn, device)\n",
        "            #d_real_loss = real_loss(d_real_logits_out, smooth=True)\n",
        "\n",
        "            # Fake images\n",
        "            with torch.no_grad():\n",
        "                # Generate a batch of random latent vectors\n",
        "                z = np.random.uniform(-1, 1, size=(dl.batch_size, z_size))\n",
        "                z = torch.from_numpy(z).float().to(device)\n",
        "                # Generate batch of fake images\n",
        "                fake_images = g(z)\n",
        "            # feed fake-images to discriminator and compute the\n",
        "            # fake_loss (i.e. target label = 0)\n",
        "            d_fake_logits_out = d(fake_images)\n",
        "            d_fake_loss = fake_loss(d_fake_logits_out, loss_fn, device)\n",
        "            #d_fake_loss = fake_loss(d_fake_logits_out)\n",
        "            # Compute total discriminator loss\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "            # Backpropogate through discriminator\n",
        "            d_loss.backward()\n",
        "            d_optim.step()\n",
        "            # Save discriminator batch loss\n",
        "            d_running_batch_loss += d_loss\n",
        "\n",
        "            ## ----------------------------------------------------------------\n",
        "            ## Train generator, compute the generator loss which is a measure\n",
        "            ## of how successful the generator is in tricking the discriminator\n",
        "            ## and finally back-propogate generator loss\n",
        "            ## ----------------------------------------------------------------\n",
        "\n",
        "            # Reset gradients\n",
        "            g_optim.zero_grad()\n",
        "\n",
        "            # Generate a batch of random latent vectors\n",
        "            #z = torch.rand(size=(dl.batch_size, z_size)).to(device)\n",
        "            z = np.random.uniform(-1, 1, size=(dl.batch_size, z_size))\n",
        "            z = torch.from_numpy(z).float().to(device)\n",
        "            # Generate a batch of fake images, feed them to discriminator\n",
        "            # and compute the generator loss as real_loss\n",
        "            # (i.e. target label = 1)\n",
        "            fake_images = g(z)\n",
        "            g_logits_out = d(fake_images)\n",
        "            g_loss = real_loss(g_logits_out, loss_fn, device)\n",
        "            #g_loss = real_loss(g_logits_out)\n",
        "            # Backpropogate thorugh generator\n",
        "            g_loss.backward()\n",
        "            g_optim.step()\n",
        "            # Save discriminator batch loss\n",
        "            g_running_batch_loss += g_loss\n",
        "\n",
        "            # Display training stats for every 200 batches\n",
        "            if curr_batch % 400 == 0 and verbose:\n",
        "                print(f'\\tBatch [{curr_batch:>4}/{len(dl):>4}] - d_batch_loss: {d_loss.item():.6f}\\tg_batch_loss: {g_loss.item():.6f}')\n",
        "\n",
        "        # Compute epoch losses as total_batch_loss/number_of_batches\n",
        "        d_epoch_loss = d_running_batch_loss.item()/len(dl)\n",
        "        g_epoch_loss = g_running_batch_loss.item()/len(dl)\n",
        "        d_losses.append(d_epoch_loss)\n",
        "        g_losses.append(g_epoch_loss)\n",
        "\n",
        "        # Display training stats for every 200 batches\n",
        "        print(f'epoch_d_loss: {d_epoch_loss:.6f} \\tepoch_g_loss: {g_epoch_loss:.6f}')\n",
        "\n",
        "        # Generate fake images from fixed latent vector using the trained\n",
        "        # generator so far and save images for latter viewing\n",
        "        g.eval()\n",
        "        fixed_samples.append(g(fixed_z).detach().cpu())\n",
        "\n",
        "    # Finally write generated fake images from fixed latent vector to disk\n",
        "    with open('fixed_samples.pkl', 'wb') as f:\n",
        "        pkl.dump(fixed_samples, f)\n",
        "\n",
        "    return d_losses, g_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparar y Realizar el Entrenamiento\n"
      ],
      "metadata": {
        "id": "wX0iFTh7Z1CR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "303fdc7b-5996-45a7-b9f0-bfc64b9a2d24"
      },
      "outputs": [],
      "source": [
        "d = Discriminator(in_features=784, out_features=1)\n",
        "g = Generator(in_features=100, out_features=784)\n",
        "\n",
        "print(d)\n",
        "print()\n",
        "print(g)\n",
        "\n",
        "# Definimos Optimizadores Separados\n",
        "d_optim = optim.Adam(d.parameters(), lr=0.002)\n",
        "g_optim = optim.Adam(g.parameters(), lr=0.002)\n",
        "\n",
        "# Consideramos la loss BCE\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "#Entrenamiento\n",
        "n_epochs = 10\n",
        "d_losses, g_losses = train_minst_gan(d, g, d_optim, g_optim,\n",
        "                                     loss_fn, train_loader, n_epochs, device,\n",
        "                                     verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizando la Loss durante el entrenamiento"
      ],
      "metadata": {
        "id": "mkWitCxpaLGB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad1bcbf2-681b-4687-b773-72a15cadc125"
      },
      "outputs": [],
      "source": [
        "plt.plot(d_losses, label='Discriminator')\n",
        "plt.plot(g_losses, label='Generator')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualicemos cómo mejora la generación de imágenes con las épocas de entrenamiento"
      ],
      "metadata": {
        "id": "wP4UuHsEaU5i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e55287b-02e1-4cc9-a521-dbd2d86316ad"
      },
      "outputs": [],
      "source": [
        "def show_generated_images(epoch, n_cols=8):\n",
        "    # Cargamos las imágenes que guardamos\n",
        "    with open('fixed_samples.pkl', 'rb') as f:\n",
        "        saved_data = pkl.load(f)\n",
        "    epoch_data = saved_data[epoch-1]\n",
        "    # re-escalamos a 0-1\n",
        "    epoch_data = (epoch_data + 1) / 2\n",
        "    # re-shapeamos a (batch_size, channel, height, width)\n",
        "    batch_size, channel, height, width = len(epoch_data), 1, 28, 28\n",
        "    image_batch = epoch_data.view(batch_size, channel, height, width)\n",
        "    display_images(images=image_batch, n_cols=n_cols, figsize=(12, 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d79418bc-b2c1-4de7-bd6f-9610551921b5"
      },
      "outputs": [],
      "source": [
        "show_generated_images(epoch=1, n_cols=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "522b8800-4fd9-41f6-9d5b-ce7d9df840ff"
      },
      "outputs": [],
      "source": [
        "show_generated_images(epoch=n_epochs//10, n_cols=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eebbd219-2b3f-4ee9-874c-45e0186b9c31"
      },
      "outputs": [],
      "source": [
        "show_generated_images(epoch=n_epochs//2, n_cols=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f49b0841-fe28-4097-940b-3055829925d3"
      },
      "outputs": [],
      "source": [
        "show_generated_images(epoch=n_epochs, n_cols=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaa6031-41f4-4438-b4be-c504abc62bcf"
      },
      "source": [
        "## Evaluar nuestras redes\n",
        "El generador entrenado se puede usar para generar un dígito aleatorio (y random) que parecerá provenir del dataset MNIST. Para esta etapa, podemos olvidarnos del discriminator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28e16d25-d080-492e-966f-43186a4ace3e"
      },
      "outputs": [],
      "source": [
        "# Traemos el generador a cpu y lo ponemos en modo eval\n",
        "g.to('cpu')\n",
        "g.eval()\n",
        "# Entregamos un vector latente random, de dimensión 100, para generar una imagen falsa.\n",
        "z = np.random.uniform(-1, 1, size=(1, 100))\n",
        "z = torch.from_numpy(z).float()\n",
        "print(\"Semilla de la Generación\", z)\n",
        "fake_image = g(z)\n",
        "# Reshapeamos y la mostramos\n",
        "fake_image = fake_image.view(1, 1, 28, 28).detach()\n",
        "display_images(fake_image, n_cols=1, figsize=(2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluar si el modelo está aprendiendo alguna estructura subyacente\n",
        "En otras palabras, samplearemos aleatoriamente muchos datos, y veremos de qué clase son los dígitos generados (apoyándonos con nuestro clasificador previamente entrenado)"
      ],
      "metadata": {
        "id": "VuUrAlOxgTJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "\n",
        "\n",
        "def analyze_gan_distribution(generator, classifier, n_samples=100):\n",
        "    # Generate latent vectors and images\n",
        "    z_vectors = np.random.uniform(-1, 1, size=(n_samples, 100))\n",
        "    z_tensors = torch.from_numpy(z_vectors).float()\n",
        "\n",
        "    # Generate images\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(z_tensors)\n",
        "        fake_images = fake_images.view(-1, 1, 28, 28)\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = classifier(fake_images)\n",
        "        predicted_labels = torch.argmax(predictions, dim=1).numpy()\n",
        "\n",
        "    # Create a grid of subplots\n",
        "    num_rows = int(np.ceil(n_samples / 5))\n",
        "    fig, axes = plt.subplots(num_rows, 5, figsize=(15, num_rows*3))\n",
        "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
        "\n",
        "    for j in range(n_samples):\n",
        "        fake_image = fake_images[j].squeeze().detach()\n",
        "        axes[j].imshow(fake_image, cmap='gray')\n",
        "        axes[j].set_title(f'Predicted Label: {predicted_labels[j]}')\n",
        "        axes[j].axis('off')  # Hide axes\n",
        "\n",
        "    # Remove any empty subplots\n",
        "    for j in range(n_samples, num_rows*5):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Reduce dimensions of latent vectors\n",
        "    pca = PCA(n_components=2)\n",
        "    z_pca = pca.fit_transform(z_vectors)\n",
        "\n",
        "    reducer = umap.UMAP()\n",
        "    z_umap = reducer.fit_transform(z_vectors)\n",
        "\n",
        "    return z_pca, z_umap, predicted_labels\n",
        "\n",
        "# Plot results\n",
        "def plot_distributions(z_pca, z_umap, labels):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # PCA plot\n",
        "    scatter1 = ax1.scatter(z_pca[:, 0], z_pca[:, 1], c=labels, cmap='tab10')\n",
        "    ax1.set_title('PCA projection of latent space')\n",
        "    plt.colorbar(scatter1, ax=ax1)\n",
        "\n",
        "    # UMAP plot\n",
        "    scatter2 = ax2.scatter(z_umap[:, 0], z_umap[:, 1], c=labels, cmap='tab10')\n",
        "    ax2.set_title('UMAP projection of latent space')\n",
        "    plt.colorbar(scatter2, ax=ax2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OzAI9rxsMHLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el Clasificador Pre-Entrenado\n",
        "classifier = MNISTClassifier()\n",
        "classifier.load_state_dict(torch.load('mnist_classifier.pth'))\n",
        "classifier.eval()"
      ],
      "metadata": {
        "id": "YZX7nr2SgrjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and analyze samples\n",
        "z_pca, z_umap, labels = analyze_gan_distribution(g, classifier, n_samples=100)\n",
        "\n",
        "\n",
        "print(50*\"-\")\n",
        "# Plot results\n",
        "plot_distributions(z_pca, z_umap, labels)\n"
      ],
      "metadata": {
        "id": "ifNqPk3_SzKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUA-f8fCYfFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wuYh3dnRjl0K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}